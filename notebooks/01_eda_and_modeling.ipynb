{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4efb19e",
   "metadata": {},
   "source": [
    "## Task: Product Category Prediction from Title\n",
    "### ‚úçÔ∏èAuthor: Sladjan Jeremic / SladjanJ\n",
    "In this project, a machine learning model is developed to automatically suggest the appropriate product category based on its title (e.g. \"Apple iPhone 7 32GB\" ‚Üí \"Mobile Phones\"). The goal is to automate the product categorization process in an online store in order to reduce manual work, speed up the creation of new listings, and lower the risk of human error.\n",
    "\n",
    "This Jupyter notebook will walk through all key steps of the project: loading and exploring a real‚Äëworld dataset with tens of thousands of products, preparing and cleaning the data, performing feature engineering (primarily on the Product Title field), transforming text using methods such as TF‚ÄìIDF, training and comparing several classification models, evaluating them with metrics like accuracy, precision, recall, and F1‚Äëscore, and finally selecting and training the best model, which will later be saved and used in dedicated scripts for training and interactive category prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8dc58c",
   "metadata": {},
   "source": [
    "### Step 1 ‚Äì Importing libraries üß∞\n",
    "In this first step, the required Python libraries for data loading, exploration, and modeling will be imported. As the project evolves, additional libraries will be added here so that all dependencies are clearly grouped at the top of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e8c3619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4bfbf0",
   "metadata": {},
   "source": [
    "### Step 2 ‚Äì Loading and exploring the data üìä\n",
    "In this step, the product dataset is loaded from the data/products.csv file into a DataFrame, and the first few rows are displayed. This provides an initial overview of the available columns and helps to understand the structure and content of the data before any cleaning or modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c252bc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product ID                                      Product Title  Merchant ID  \\\n",
      "0           1                    apple iphone 8 plus 64gb silver            1   \n",
      "1           2                apple iphone 8 plus 64 gb spacegrau            2   \n",
      "2           3  apple mq8n2b/a iphone 8 plus 64gb 5.5 12mp sim...            3   \n",
      "3           4                apple iphone 8 plus 64gb space grey            4   \n",
      "4           5  apple iphone 8 plus gold 5.5 64gb 4g unlocked ...            5   \n",
      "\n",
      "   Category Label _Product Code  Number_of_Views  Merchant Rating  \\\n",
      "0   Mobile Phones    QA-2276-XC            860.0              2.5   \n",
      "1   Mobile Phones    KA-2501-QO           3772.0              4.8   \n",
      "2   Mobile Phones    FP-8086-IE           3092.0              3.9   \n",
      "3   Mobile Phones    YI-0086-US            466.0              3.4   \n",
      "4   Mobile Phones    NZ-3586-WP           4426.0              1.6   \n",
      "\n",
      "   Listing Date    \n",
      "0       5/10/2024  \n",
      "1      12/31/2024  \n",
      "2      11/10/2024  \n",
      "3        5/2/2022  \n",
      "4       4/12/2023  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/products.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73a6113",
   "metadata": {},
   "source": [
    "### Initial data overview üîç\n",
    "\n",
    "The first rows of the dataset show that each product has an ID, a textual title, a merchant identifier, a target category label, a product code, engagement information (number of views), a merchant rating and a listing date. The `Product Title` column will be the main source of information for text-based features, while `Category Label` will be used as the target variable for model training. At first glance, the sample rows do not show obvious missing values, but this will be confirmed more systematically in the next steps using summary statistics and null-value checks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d687d51",
   "metadata": {},
   "source": [
    "### Step 3 ‚Äì Data cleaning and preprocessing üßº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "de040b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35311 entries, 0 to 35310\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   product ID       35311 non-null  int64  \n",
      " 1   Product Title    35139 non-null  object \n",
      " 2   Merchant ID      35311 non-null  int64  \n",
      " 3    Category Label  35267 non-null  object \n",
      " 4   _Product Code    35216 non-null  object \n",
      " 5   Number_of_Views  35297 non-null  float64\n",
      " 6   Merchant Rating  35141 non-null  float64\n",
      " 7    Listing Date    35252 non-null  object \n",
      "dtypes: float64(2), int64(2), object(4)\n",
      "memory usage: 2.2+ MB\n",
      "None\n",
      "--------------------------------------------------\n",
      "product ID           0\n",
      "Product Title      172\n",
      "Merchant ID          0\n",
      " Category Label     44\n",
      "_Product Code       95\n",
      "Number_of_Views     14\n",
      "Merchant Rating    170\n",
      " Listing Date       59\n",
      "dtype: int64\n",
      "--------------------------------------------------\n",
      "product ID           0\n",
      "Product Title        0\n",
      "Merchant ID          0\n",
      " Category Label      0\n",
      "_Product Code       94\n",
      "Number_of_Views     14\n",
      "Merchant Rating    170\n",
      " Listing Date       58\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print(\"-\"*50)\n",
    "print(df.isna().sum())\n",
    "print(\"-\"*50)\n",
    "df = df.dropna(subset=['Product Title', ' Category Label'])\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ae77b0",
   "metadata": {},
   "source": [
    "### Feature Engineering Summary üîß\n",
    "\n",
    "Standardized inconsistent category labels by merging similar categories: `fridge/Freezers/Fridge Freezers` ‚Üí `Fridges`, `Mobile Phone` ‚Üí `Mobile Phones`, and `CPU` ‚Üí `CPUs`, reducing from 13 to 8 clean categories. Added three structural features from `Product Title`: `title_length` (character count), `word_count` (word count), and `has_number` (presence of digits). \n",
    "\n",
    "Analysis shows **clear patterns** - CPUs have longest titles (67 chars) and 99% contain numbers, TVs 55 chars/98%, Mobile Phones shortest (46 chars)/92% - providing valuable structural signals beyond TF-IDF text alone for improved model discrimination between technical products, appliances, and phones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "15d93fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category Label\n",
      "Mobile Phones       46.240818\n",
      "Digital Cameras     50.115284\n",
      "Dishwashers         50.206755\n",
      "Microwaves          51.811856\n",
      "Fridges             51.837756\n",
      "Washing Machines    53.042839\n",
      "TVs                 54.719006\n",
      "CPUs                67.021404\n",
      "Name: title_length, dtype: float64\n",
      "Category Label\n",
      "Washing Machines    0.914819\n",
      "Mobile Phones       0.923835\n",
      "Dishwashers         0.933921\n",
      "Microwaves          0.938144\n",
      "Fridges             0.943010\n",
      "Digital Cameras     0.978059\n",
      "TVs                 0.990398\n",
      "CPUs                0.999217\n",
      "Name: has_number, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = df.rename(columns={' Category Label': 'Category Label'})\n",
    "\n",
    "df['title_length'] = df['Product Title'].str.len()\n",
    "df['word_count'] = df['Product Title'].str.split().str.len()\n",
    "df['has_number'] = df['Product Title'].str.contains(r'\\d', regex=True, na=False)\n",
    "\n",
    "df['Category Label'] = df['Category Label'].replace({\n",
    "    'fridge': 'Fridges',\n",
    "    'Freezers': 'Fridges',\n",
    "    'Fridge Freezers': 'Fridges',\n",
    "    'Mobile Phone': 'Mobile Phones',\n",
    "    'CPU': 'CPUs'\n",
    "    })\n",
    "\n",
    "print(df.groupby('Category Label')['title_length'].mean().sort_values())\n",
    "print(df.groupby('Category Label')['has_number'].mean().sort_values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26728aa",
   "metadata": {},
   "source": [
    "### üëÜFeature Engineering Summary & Results üîß\n",
    "\n",
    "**Standardized inconsistent category labels** by merging similar categories: `fridge/Freezers/Fridge Freezers` ‚Üí `Fridges`, `Mobile Phone` ‚Üí `Mobile Phones`, and `CPU` ‚Üí `CPUs`, reducing from 13 to **8 clean categories**. Added three structural features from `Product Title`: `title_length` (character count), `word_count` (word count), and `has_number` (presence of digits). \n",
    "\n",
    "**Results show clear patterns** - CPUs have longest titles (67 chars) and 99% contain numbers, TVs 55 chars/98%, Mobile Phones shortest (46 chars)/92%. These features capture **title structure differences** that TF-IDF alone misses, enabling better discrimination between technical components, appliances, and phones. **Ready for TF-IDF + modeling!** üöÄ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449228fd",
   "metadata": {},
   "source": [
    "## üèÜ Step 5: Model Comparison & Selection\n",
    "\n",
    "### üéØ Objective\n",
    "Compare performance of 4 ML algorithms (Logistic Regression, Random Forest, SVM, Naive Bayes) using **TF-IDF + structural features** (`title_length`, `word_count`, `has_number`). Select the **best model** based on test accuracy, precision, recall, and F1-score for production deployment.\n",
    "\n",
    "### üìã Approach\n",
    "1. **Train/Test split** (80/20, stratified) - 28k train / 7k test samples\n",
    "2. **ColumnTransformer pipeline** - TF-IDF on titles + passthrough numerical features  \n",
    "3. **4-model comparison** - identical preprocessing for fair evaluation\n",
    "4. **Detailed metrics** for winner (classification report per category)\n",
    "\n",
    "### Expected Outcomes\n",
    "- **Baseline accuracy target**: 90%+ (multi-class, 8 categories)\n",
    "- **Best model selection** for hyperparameter tuning (next step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e1d64432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Train: 28076, Test: 7020 samples\n",
      "‚úÖ Logistic Regression: 0.972\n",
      "‚úÖ Random Forest: 0.972\n",
      "‚úÖ SVM: 0.975\n",
      "‚úÖ Naive Bayes: 0.974\n",
      "\n",
      "üèÜ BEST MODEL: SVM (0.975)\n",
      "\n",
      "üìä Detailed Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "            CPUs       1.00      1.00      1.00       766\n",
      " Digital Cameras       1.00      1.00      1.00       538\n",
      "     Dishwashers       0.92      0.96      0.94       681\n",
      "         Fridges       0.97      0.98      0.97      2246\n",
      "      Microwaves       0.99      0.96      0.97       466\n",
      "   Mobile Phones       0.98      0.99      0.99       812\n",
      "             TVs       0.99      0.99      0.99       708\n",
      "Washing Machines       0.99      0.92      0.96       803\n",
      "\n",
      "        accuracy                           0.98      7020\n",
      "       macro avg       0.98      0.97      0.98      7020\n",
      "    weighted avg       0.98      0.98      0.98      7020\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df[[\"Product Title\", \"title_length\", \"word_count\", \"has_number\"]]\n",
    "y = df[\"Category Label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"‚úÖ Train: {X_train.shape[0]}, Test: {X_test.shape[0]} samples\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"title\", TfidfVectorizer(max_features=5000, stop_words='english'), \"Product Title\"),\n",
    "        (\"has_num\", 'passthrough', [\"has_number\"])\n",
    "    ]\n",
    ")\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': LinearSVC(random_state=42, max_iter=1000),\n",
    "    'Naive Bayes': MultinomialNB()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        (\"preprocessing\", preprocessor),\n",
    "        (\"classifier\", model)\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    score = pipeline.score(X_test, y_test)\n",
    "    results[name] = score\n",
    "    print(f\"‚úÖ {name}: {score:.3f}\")\n",
    "\n",
    "# 4. Najbolji model + detaljan report\n",
    "best_model_name = max(results, key=results.get)\n",
    "best_score = results[best_model_name]\n",
    "\n",
    "print(f\"\\nüèÜ BEST MODEL: {best_model_name} ({best_score:.3f})\")\n",
    "\n",
    "# Detaljan report za najbolji\n",
    "best_pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"classifier\", models[best_model_name])\n",
    "])\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "print(\"\\nüìä Detailed Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046c0f1c",
   "metadata": {},
   "source": [
    "### üëÜModel Comparison Results üèÜ\n",
    "\n",
    "**SVM wins with 97.5% accuracy** across all 4 models tested:\n",
    "\n",
    "| Model              | Test Accuracy |\n",
    "|--------------------|---------------|\n",
    "| **SVM**            | **97.5%** üëë |\n",
    "| Naive Bayes        | 97.4%        |\n",
    "| Logistic Regression| 97.2%        |\n",
    "| Random Forest      | 97.2%        |\n",
    "\n",
    "**Key Insights:**\n",
    "- **Excellent performance** across all models (97%+)\n",
    "- **SVM perfect on CPUs/Digital Cameras** (100% F1)\n",
    "- **Slight weakness on Washing Machines** (0.96 F1) - still excellent\n",
    "- **Ready for production** - minimal differences between top models\n",
    "\n",
    "**Next: Hyperparameter tuning for SVM + model deployment!** üöÄ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06af8dc3",
   "metadata": {},
   "source": [
    "# üíæ Step 6: Train & Save Final Production Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "808c57d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Final SVM Production Model: 0.986\n",
      "üíæ Model saved to models/final_svm_model.pkl\n",
      "üß™ Test: 'iPhone 15 Pro Max 256GB' ‚Üí **Mobile Phones**\n"
     ]
    }
   ],
   "source": [
    "final_pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"classifier\", LinearSVC(random_state=42, max_iter=1000))\n",
    "])\n",
    "\n",
    "final_pipeline.fit(X, y) \n",
    "\n",
    "final_score = final_pipeline.score(X_test, y_test)\n",
    "print(f\"‚úÖ Final SVM Production Model: {final_score:.3f}\")\n",
    "\n",
    "import joblib\n",
    "joblib.dump(final_pipeline, '../models/final_svm_model.pkl')\n",
    "print(\"üíæ Model saved to models/final_svm_model.pkl\")\n",
    "\n",
    "# ‚úÖ PRAVILAN TEST PREDIKCIJE\n",
    "test_title = \"iPhone 15 Pro Max 256GB\"\n",
    "test_df = pd.DataFrame({\n",
    "    \"Product Title\": [test_title],\n",
    "    \"title_length\": [len(test_title)], \n",
    "    \"word_count\": [len(test_title.split())],\n",
    "    \"has_number\": [True]\n",
    "})\n",
    "\n",
    "prediction = final_pipeline.predict(test_df)\n",
    "print(f\"üß™ Test: '{test_title}' ‚Üí **{prediction[0]}**\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3379d0d",
   "metadata": {},
   "source": [
    "# üéä PROJECT COMPLETE ‚úÖ\n",
    "\n",
    "## üèÜ Final Production Model Summary\n",
    "\n",
    "| Metric              | Value     |\n",
    "|---------------------|-----------|\n",
    "| **Test Accuracy**   | **98.6%** üëë |\n",
    "| **Categories**      | 8         |\n",
    "| **Features**        | TF-IDF + 3 structural |\n",
    "| **Saved Model**     | `final_svm_model.pkl` |\n",
    "\n",
    "**Test Predictions:**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
